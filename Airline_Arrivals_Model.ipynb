{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Airline_Arrivals_Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgv3+34stfLAK7xlQJ02D3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trandangtrungduc/BasicMachineLearningTask/blob/main/Airline_Arrivals_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI8mZHP2X0Qy"
      },
      "source": [
        "#  **TABLE OF CONTENTS**\n",
        "\n",
        "---\n",
        "## **1. Import librabries and data preprocessing**\n",
        "## **2. Apply model without feature selection**\n",
        "> ### 2.1 Hold out\n",
        "> ### 2.2 Naive Bayes\n",
        "> ### 2.3 Logistic Regression\n",
        "> ### 2.4 Decision Tree\n",
        "> ### 2.5 Random Forest\n",
        "> ### 2.6 Gradient Boosting\n",
        "> ### 2.7 Support Vector Machine\n",
        "## **3. Apply model with PCA**\n",
        "> ### 3.1 Apply PCA with component equal to the number of columns of X minus 1\n",
        "> ### 3.2 Hold out\n",
        "> ### 3.3 Naive Bayes\n",
        "> ### 3.4 Logistic Regression\n",
        "> ### 3.5 Decision Tree\n",
        "> ### 3.6 Random Forest\n",
        "> ### 3.7 Gradient Boosting\n",
        "> ### 3.8 Support Vector Machine\n",
        "## **4. Apply model with KBest**\n",
        "> ### 4.1 Apply KBest with k equal to the number of columns of X minus 1\n",
        "> ### 4.2 Hold out\n",
        "> ### 4.3 Naive Bayes\n",
        "> ### 4.4 Logistic Regression\n",
        "> ### 4.5 Decision Tree\n",
        "> ### 4.6 Random Forest\n",
        "> ### 4.7 Gradient Boosting\n",
        "> ### 4.8 Support Vector Machine\n",
        "## **5. Apply model with RFE**\n",
        "> ### 5.1 Naive Bayes\n",
        "> ### 5.2 Logistic Regression\n",
        "> ### 5.3 Decision Tree\n",
        "> ### 5.4 Random Forest\n",
        "> ### 5.5 Gradient Boosting\n",
        "> ### 5.6 Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-KN6BzAYPV1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **1. Import librabries and data preprocessing**\n",
        "\n",
        "> Connect Google Drive to Google Colab and import necessary librabries\n",
        "\n",
        "> Load the data in file csv from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEGdskjhPse1",
        "outputId": "711a718b-e760-4546-a71a-61f59fa42951"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTRgjgD0Pxzj"
      },
      "source": [
        "import pandas as pd # Librabry for table data\n",
        "import numpy as np # Librabry for algebra\n",
        "# Library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Librabry sklearn model selection \n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
        "# Librabry for feature selection\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, RFE, f_classif\n",
        "# Librabry for algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "JblszE8kP3q0",
        "outputId": "647a7bf6-7eca-4d88-e186-644c4fe5fa9c"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data/new_2007.csv') # Load data from Google Drive\n",
        "df.head() # See some information at the top of dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Month</th>\n",
              "      <th>DayofMonth</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>UniqueCarrier</th>\n",
              "      <th>FlightNum</th>\n",
              "      <th>TailNum</th>\n",
              "      <th>ArrDelay</th>\n",
              "      <th>DepDelay</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Distance</th>\n",
              "      <th>TaxiIn</th>\n",
              "      <th>TaxiOut</th>\n",
              "      <th>Diverted</th>\n",
              "      <th>ArrDelay_categorical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>2891</td>\n",
              "      <td>N351</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>ONT</td>\n",
              "      <td>389</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1918.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>462</td>\n",
              "      <td>N370</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>PDX</td>\n",
              "      <td>479</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1230.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>1355</td>\n",
              "      <td>N364</td>\n",
              "      <td>26.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>PDX</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>831.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>2278</td>\n",
              "      <td>N480</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>PDX</td>\n",
              "      <td>479</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1430.0</td>\n",
              "      <td>WN</td>\n",
              "      <td>2386</td>\n",
              "      <td>N611SW</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>SMF</td>\n",
              "      <td>PDX</td>\n",
              "      <td>479</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Month  DayofMonth  ...  TaxiOut  Diverted ArrDelay_categorical\n",
              "0           0      1           1  ...       11         0                    0\n",
              "1           1      1           1  ...        6         0                    0\n",
              "2           3      1           1  ...        8         0                    0\n",
              "3           4      1           1  ...        9         0                    0\n",
              "4           5      1           1  ...        7         0                    0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoQCTQIRUiXD"
      },
      "source": [
        "df = df.drop(columns=['TailNum', 'Origin', 'Dest','Unnamed: 0','ArrDelay','DepDelay']) # Drop categorical features which are analyzed at Analysis section "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0IP_AMuXCNF"
      },
      "source": [
        "X = df.drop(['ArrDelay_categorical', 'Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'], axis=1) # Drop available features to convert to categorical feature\n",
        "y = df[\"ArrDelay_categorical\"] # Target column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCqYnnkHuUQC"
      },
      "source": [
        "Categorical_features = df[['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier']]\n",
        "one_hot_encoding = pd.get_dummies(data= Categorical_features, columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'])\n",
        "new_X = pd.concat([X, one_hot_encoding], axis=1, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXZYtFJXYhsN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **2. Apply model without feature selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz3Wpr8jpFMq"
      },
      "source": [
        "### 2.1 Hold out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zop1BAkSo37l"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(new_X, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTqG2W1fbS3v"
      },
      "source": [
        "### 2.2 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geYfksWqXnbR",
        "outputId": "2d9fb80f-b73e-4e94-eece-41792bc4d55e"
      },
      "source": [
        "logreg = LogisticRegression() # Initialize Logistic Regression\n",
        "logreg.fit(X_train, y_train) # Train model \n",
        "y_pred = logreg.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.00      0.00      0.00     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.49      0.50      0.50   1061313\n",
            "weighted avg       0.96      0.98      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjaZIJWZbXZB"
      },
      "source": [
        "### 2.3 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfT7lthKXs4n",
        "outputId": "e5a20558-1f81-43c8-d962-fd342e0e1715"
      },
      "source": [
        "decisiontree = DecisionTreeClassifier() # Initialize Decision Tree\n",
        "decisiontree.fit(X_train, y_train) # Train model\n",
        "y_pred = decisiontree.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98   1040663\n",
            "           1       0.16      0.17      0.17     20650\n",
            "\n",
            "    accuracy                           0.97   1061313\n",
            "   macro avg       0.57      0.58      0.57   1061313\n",
            "weighted avg       0.97      0.97      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByUrIJtVbdDW"
      },
      "source": [
        "### 2.4 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXrjMgskXye1",
        "outputId": "9186cce1-177e-49a3-c185-a78623fd9c34"
      },
      "source": [
        "randomforest = RandomForestClassifier() # Initialize Random Forest\n",
        "randomforest.fit(X_train, y_train) # Train model\n",
        "y_pred = randomforest.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.99      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggGVZU5Vbf1j"
      },
      "source": [
        "### 2.5 GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUCHs4szXy1t",
        "outputId": "fa8f4c99-bf3b-4bba-a0a4-6ed7ebc5ec31"
      },
      "source": [
        "gbk = GradientBoostingClassifier() # Initialize GradientBoosting\n",
        "gbk.fit(X_train, y_train) # Train model\n",
        "y_pred = gbk.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXKZxcYbjCJ"
      },
      "source": [
        "### 2.6 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MsNcVdyX31t",
        "outputId": "71337111-c661-452d-ef3d-8d817806628f"
      },
      "source": [
        "svm = LinearSVC(class_weight='balanced') # Initialize Support Vector Machine\n",
        "svm.fit(X_train, y_train) # Train model\n",
        "y_pred = svm.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyBLJFZebo2q"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **3. Apply model with PCA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9fyBZ4ZbufU"
      },
      "source": [
        "### 3.1 Apply PCA with component equal to the number of columns of X minus 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqpz8WhLluyb"
      },
      "source": [
        "pca = PCA(n_components = X.shape[1]-1) # Configure PCA\n",
        "X_PCA = pca.fit_transform(X) # Apply pca\n",
        "X_PCA = pd.DataFrame(X_PCA) # Convert to dataframe\n",
        "X_PCA = X_PCA.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_PCA = X_PCA.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index column\n",
        "new_X_PCA = pd.concat([X_PCA, one_hot_encoding], axis=1, sort=False) # Concatenate two columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvB3sTu7d7NK"
      },
      "source": [
        "### 3.2 Hold out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouw4rzEGlxCA"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(new_X_PCA, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf3dR-pheDp8"
      },
      "source": [
        "### 3.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ5Kp-b_YTv9",
        "outputId": "280e3d0d-1d36-4c5a-87d3-7eb00b35353d"
      },
      "source": [
        "logreg = LogisticRegression() # Initialize Logistic Regression\n",
        "logreg.fit(X_train, y_train) # Train model \n",
        "y_pred = logreg.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.00      0.00      0.00     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.49      0.50      0.50   1061313\n",
            "weighted avg       0.96      0.98      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh2CWRuHeJLL"
      },
      "source": [
        "### 3.4 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bc89fMYYT2Z",
        "outputId": "cdfd3e46-94ce-4875-9bef-b4279c1b51df"
      },
      "source": [
        "decisiontree = DecisionTreeClassifier() # Initialize Decision Tree\n",
        "decisiontree.fit(X_train, y_train) # Train model\n",
        "y_pred = decisiontree.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98   1040663\n",
            "           1       0.15      0.17      0.16     20650\n",
            "\n",
            "    accuracy                           0.97   1061313\n",
            "   macro avg       0.57      0.58      0.57   1061313\n",
            "weighted avg       0.97      0.97      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJmweKeteMnA"
      },
      "source": [
        "### 3.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3xWH_mYYT_m",
        "outputId": "edbaf2fd-180a-49c4-ac7d-3251c21d296c"
      },
      "source": [
        "randomforest = RandomForestClassifier() # Initialize Random Forest\n",
        "randomforest.fit(X_train, y_train) # Train model\n",
        "y_pred = randomforest.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.96      0.10      0.18     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.97      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvePvVtYePzw"
      },
      "source": [
        "### 3.6 GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhPNG9T9YUaZ",
        "outputId": "86047227-16f7-4af8-fb52-ad53992a8919"
      },
      "source": [
        "gbk = GradientBoostingClassifier() # Initialize GradientBoosting\n",
        "gbk.fit(X_train, y_train) # Train model\n",
        "y_pred = gbk.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.92      0.10      0.18     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.95      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9KKwRKSeSqk"
      },
      "source": [
        "### 3.7 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I46_-70EeRTw",
        "outputId": "9a840ee1-260c-4fb9-fd8a-f809e53979e1"
      },
      "source": [
        "svm = LinearSVC(class_weight='balanced') # Initialize Support Vector Machine\n",
        "svm.fit(X_train, y_train) # Train model\n",
        "y_pred = svm.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijdn38VpeWmO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **4. Apply model with KBest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsN5ux1qeivw"
      },
      "source": [
        "### 4.1 Apply KBest with k equal to the number of columns of X minus 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXVICONtTQPo"
      },
      "source": [
        "X_KBest = SelectKBest(f_classif, k=X.shape[1]-1).fit_transform(X, y) # ANOVA F-value between feature for classification tasks \n",
        "X_KBest = pd.DataFrame(X_KBest) # Convert to dataframe\n",
        "X_KBest = X_KBest.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Drop index column\n",
        "X_KBest = X_KBest.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1)  # Drop index column\n",
        "new_X_KBest = pd.concat([X_KBest, one_hot_encoding], axis=1, sort=False)# Concatenate two columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKmCs-mexEf"
      },
      "source": [
        "### 4.2 Holdout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc14Oz_HUBK1"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(new_X_KBest, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8mFn2X8e32f"
      },
      "source": [
        "### 4.3 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psf38S6EUaRx",
        "outputId": "18b713e3-2c95-4fc7-fee2-49fc0974a64c"
      },
      "source": [
        "logreg = LogisticRegression() # Initialize Logistic Regression\n",
        "logreg.fit(X_train, y_train) # Train model \n",
        "y_pred = logreg.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.99      0.03      0.06     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.52      0.52   1061313\n",
            "weighted avg       0.98      0.98      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGigACh-e732"
      },
      "source": [
        "### 4.4 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edbOb5iNUatG",
        "outputId": "5808b591-855c-46c7-accd-19dee26f3bb3"
      },
      "source": [
        "decisiontree = DecisionTreeClassifier() # Initialize Decision Tree\n",
        "decisiontree.fit(X_train, y_train) # Train model\n",
        "y_pred = decisiontree.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98   1040663\n",
            "           1       0.16      0.17      0.16     20650\n",
            "\n",
            "    accuracy                           0.97   1061313\n",
            "   macro avg       0.57      0.58      0.57   1061313\n",
            "weighted avg       0.97      0.97      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovtlz_6Qe_yS"
      },
      "source": [
        "### 4.5 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9yV1nkEUaz9",
        "outputId": "10b201ec-4636-4f00-8ffc-e5e51e6f6d6a"
      },
      "source": [
        "randomforest = RandomForestClassifier() # Initialize Random Forest\n",
        "randomforest.fit(X_train, y_train) # Train model\n",
        "y_pred = randomforest.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.96      0.11      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.97      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pur5r0F7fHDH"
      },
      "source": [
        "### 4.6 GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRPIYfEEUa6L",
        "outputId": "e1a5cddf-6fe8-4583-bd33-9ea5f92ea046"
      },
      "source": [
        "gbk = GradientBoostingClassifier() # Initialize GradientBoosting\n",
        "gbk.fit(X_train, y_train) # Train model\n",
        "y_pred = gbk.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oec5EgTyfLY9"
      },
      "source": [
        "### 4.7 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3QhDTmUbAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491d730b-45e5-4be5-88c1-513a0ee69a6d"
      },
      "source": [
        "svm = LinearSVC(class_weight='balanced') # Initialize Support Vector Machine\n",
        "svm.fit(X_train, y_train) # Train model\n",
        "y_pred = svm.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mubG4HEkfR72"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **5. Apply model with RFE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6kaDTaXfdCm"
      },
      "source": [
        "### 5.1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKzDldX1UrKq",
        "outputId": "eca70769-8b60-442e-f0bd-307fea88f013"
      },
      "source": [
        "model = LogisticRegression() # Initialize Logistic Regression\n",
        "rfe = RFE(model, X.shape[1]-1) # Configure RFE \n",
        "X_RFE = rfe.fit_transform(X, y) # Apply rfe for data\n",
        "X_RFE = pd.DataFrame(X_RFE) # Convert to dataframe\n",
        "X_RFE = X_RFE.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_RFE = X_RFE.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index column\n",
        "new_X_RFE = pd.concat([X_RFE, one_hot_encoding], axis=1, sort=False) # New input X\n",
        "X_train, X_val, y_train, y_val = train_test_split(new_X_RFE, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set\n",
        "logreg = LogisticRegression() # Initialize Logistic Regression\n",
        "logreg.fit(X_train, y_train) # Train model\n",
        "y_pred = logreg.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.98      0.03      0.06     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.98      0.51      0.52   1061313\n",
            "weighted avg       0.98      0.98      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhsEpcxBfiXE"
      },
      "source": [
        "### 5.2 Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD5_NCewWL1o",
        "outputId": "b4fdc12a-6552-4119-8439-b657fa54c5ee"
      },
      "source": [
        "model = DecisionTreeClassifier() # Initialize Decision Tree\n",
        "rfe = RFE(model, X_train.shape[1]-1) # Configure RFE\n",
        "X_RFE = rfe.fit_transform(X, y) # Apply rfe for data\n",
        "X_RFE = pd.DataFrame(X_RFE) # Convert to dataframe\n",
        "X_RFE = X_RFE.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_RFE = X_RFE.drop('index', axis=1)  # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1)  # Drop index column\n",
        "new_X_RFE = pd.concat([X_RFE, one_hot_encoding], axis=1, sort=False) # New input X\n",
        "X_train, X_val, y_train, y_val = train_test_split(new_X_RFE, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set\n",
        "X = rfe.fit_transform(X,y) # Feature selection with RFE \n",
        "decisiontree = DecisionTreeClassifier() # Initialize Decision Tree\n",
        "decisiontree.fit(X_train, y_train) # Train model\n",
        "y_pred = decisiontree.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98   1040663\n",
            "           1       0.16      0.18      0.17     20650\n",
            "\n",
            "    accuracy                           0.97   1061313\n",
            "   macro avg       0.57      0.58      0.58   1061313\n",
            "weighted avg       0.97      0.97      0.97   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkbs3Dufl8T"
      },
      "source": [
        "### 5.3 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOyvAvxuWNnz",
        "outputId": "3edc8aa9-0852-4569-cb86-12e021ce4070"
      },
      "source": [
        "model = RandomForestClassifier() # Initialize Random Forest\n",
        "rfe = RFE(model, X_train.shape[1]-2) # Configure RFE\n",
        "X_RFE = rfe.fit_transform(X, y) # Apply rfe for data\n",
        "X_RFE = pd.DataFrame(X_RFE) # Convert to dataframe\n",
        "X_RFE = X_RFE.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_RFE = X_RFE.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1)  # Drop index column\n",
        "new_X_RFE = pd.concat([X_RFE, one_hot_encoding], axis=1, sort=False) # New input X\n",
        "X_train, X_val, y_train, y_val = train_test_split(new_X_RFE, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set\n",
        "X = rfe.fit_transform(X,y) # Feature selection with RFE \n",
        "randomforest = RandomForestClassifier() # Initialize Random Forest\n",
        "randomforest.fit(X_train, y_train) # Train model\n",
        "y_pred = randomforest.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.99      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Iv2vTufonB"
      },
      "source": [
        "### 5.4 GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M2tB3fXWQjQ",
        "outputId": "c8a19219-3dfb-4e0b-f10a-687fa04b822d"
      },
      "source": [
        "model = GradientBoostingClassifier() # Initialize Random Forest\n",
        "rfe = RFE(model, X_train.shape[1]-2) # Configure RFE\n",
        "X_RFE = rfe.fit_transform(X, y) # Apply rfe for data\n",
        "X_RFE = pd.DataFrame(X_RFE) # Convert to dataframe\n",
        "X_RFE = X_RFE.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_RFE = X_RFE.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index column\n",
        "new_X_RFE = pd.concat([X_RFE, one_hot_encoding], axis=1, sort=False) # New input X\n",
        "X_train, X_val, y_train, y_val = train_test_split(new_X_RFE, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set\n",
        "gbk = GradientBoostingClassifier() # Initialize GradientBoosting\n",
        "gbk.fit(X_train, y_train) # Train model\n",
        "y_pred = gbk.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_8rOIpfrts"
      },
      "source": [
        "### 5.5 Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Wu5_QpWRg-",
        "outputId": "dcc09af4-6b25-4747-b706-805110657879"
      },
      "source": [
        "model = LinearSVC() # Initialize Support Vector Machine\n",
        "rfe = RFE(model, X_train.shape[1]-2) # Configure RFE \n",
        "X_RFE = rfe.fit_transform(X, y) # Apply rfe for data\n",
        "X_RFE = pd.DataFrame(X_RFE) # Convert to dataframe\n",
        "X_RFE = X_RFE.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_RFE = X_RFE.drop('index', axis=1) # Drop index columns\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index columns\n",
        "new_X_RFE = pd.concat([X_RFE, one_hot_encoding], axis=1, sort=False) # New input X\n",
        "X_train, X_val, y_train, y_val = train_test_split(new_X_RFE, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set\n",
        "svm = LinearSVC(class_weight='balanced') # Initialize Support Vector Machine\n",
        "svm.fit(X_train, y_train) # Train model\n",
        "y_pred = svm.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn7Pv4DL5vSi"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##  **6. Naive Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NzCgYE7rFIG"
      },
      "source": [
        "### 6.1 Naive Bayes without feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O989ouJ0rMgb"
      },
      "source": [
        "df_down = df.sample(frac=0.3) # Random sampling \n",
        "X_6 = df_down.drop(['ArrDelay_categorical', 'Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'], axis=1) # Drop available features to convert to categorical feature\n",
        "y_6 = df_down[\"ArrDelay_categorical\"] # Target column\n",
        "Categorical_features = df_down[['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier']]\n",
        "one_hot_encoding = pd.get_dummies(data= Categorical_features, columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'])\n",
        "X_6 = pd.DataFrame(X_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1aIcYvKreNH"
      },
      "source": [
        "### 6.2 Hold out without feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpjha6oSrdr7"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_6, y_6, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TAsFZzinxRe",
        "outputId": "c3d1d369-bb61-4283-a6a4-b7727bf3eb0a"
      },
      "source": [
        "gaussian = GaussianNB() # Initialize Naive Bayes\n",
        "gaussian.fit(X_train, y_train) # Train model\n",
        "y_pred = gaussian.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99    312348\n",
            "           1       1.00      0.10      0.18      6046\n",
            "\n",
            "    accuracy                           0.98    318394\n",
            "   macro avg       0.99      0.55      0.59    318394\n",
            "weighted avg       0.98      0.98      0.98    318394\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_c7KKY7qGRt"
      },
      "source": [
        "### 6.3 Naive Bayes with PCA and down data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_togwXjXZJo"
      },
      "source": [
        "X_PCA = df_down.drop(['ArrDelay_categorical', 'Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'], axis=1) # Drop available features to convert to categorical feature\n",
        "y_PCA = df_down[\"ArrDelay_categorical\"] # Target column\n",
        "pca = PCA(n_components = X_PCA.shape[1]-1) # Select the number of dimension\n",
        "X_PCA = pca.fit_transform(X_PCA) # Apply PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9NdzUUeXgEV"
      },
      "source": [
        "Categorical_features = df_down[['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier']]\n",
        "one_hot_encoding = pd.get_dummies(data= Categorical_features, columns=['Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier'])\n",
        "X_PCA = pd.DataFrame(X_PCA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJS9ihvAYTN6"
      },
      "source": [
        "X_PCA = X_PCA.reset_index()\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_PCA = X_PCA.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index column\n",
        "new_X_PCA = pd.concat([X_PCA, one_hot_encoding], axis=1, sort=False)  # Concatenate two columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3tqHViUqQUX"
      },
      "source": [
        "### 6.4 Hold out (PCA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suWxc9cfeHoR"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(new_X_PCA, y_PCA, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BvZ17GXYToM",
        "outputId": "d36a0cd2-96aa-4235-9e17-940ca6242008"
      },
      "source": [
        "gaussian = GaussianNB() # Initialize Naive Bayes\n",
        "gaussian.fit(X_train, y_train) # Train model\n",
        "y_pred = gaussian.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94    312348\n",
            "           1       0.05      0.27      0.08      6046\n",
            "\n",
            "    accuracy                           0.88    318394\n",
            "   macro avg       0.52      0.58      0.51    318394\n",
            "weighted avg       0.97      0.88      0.92    318394\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZNwy5wZqcky"
      },
      "source": [
        "### 6.5 Naive Bayes with KBest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXag9SEMorMg"
      },
      "source": [
        "X_KBest = SelectKBest(f_classif, k=X.shape[1]-1).fit_transform(X, y) # ANOVA F-value between feature for classification tasks \n",
        "X_KBest = pd.DataFrame(X_KBest) # Convert to dataframe\n",
        "X_KBest = X_KBest.reset_index() # Reset index\n",
        "one_hot_encoding = one_hot_encoding.reset_index() # Reset index\n",
        "X_KBest = X_KBest.drop('index', axis=1) # Drop index column\n",
        "one_hot_encoding = one_hot_encoding.drop('index', axis=1) # Drop index column\n",
        "new_X_KBest = pd.concat([X_KBest, one_hot_encoding], axis=1, sort=False) # Concatenate two columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e2GHK0JqjtD"
      },
      "source": [
        "### 6.6 Hold out (KBest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paZqP955oshC"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(new_X_KBest, y, test_size = 0.2, random_state = 0) # Divide into 2 train test and test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slwrfOa0onSU",
        "outputId": "6dd3d3eb-2fd1-4a38-c907-08f5203df781"
      },
      "source": [
        "gaussian = GaussianNB() # Initialize Naive Bayes\n",
        "gaussian.fit(X_train, y_train) # Train model\n",
        "y_pred = gaussian.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate result of model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97   1040663\n",
            "           1       0.09      0.24      0.13     20650\n",
            "\n",
            "    accuracy                           0.94   1061313\n",
            "   macro avg       0.54      0.60      0.55   1061313\n",
            "weighted avg       0.97      0.94      0.95   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZqnF5LoquEp"
      },
      "source": [
        "### 6.7 Naive Bayes with RFE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo74Rk2SlQMP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##  **7. GridSearchCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8uTxY9FVL_I"
      },
      "source": [
        "### 7.1 Logistic Regression with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhpbUVbF50kx",
        "outputId": "8d7e80df-b252-40c7-b841-0372fbb7f805"
      },
      "source": [
        "param_grid = {'penalty': ['l2'],\n",
        "             'C' : [0.7,0.8,0.9],\n",
        "             'solver': ['lbfgs', 'liblinear'],\n",
        "             'class_weight': [{1:0.6, 0:0.4}, {1:0.7, 0:0.3}, {1:0.8, 0:0.2}]} # Desired parameter\n",
        "logreg_grid = GridSearchCV(estimator=LogisticRegression(), # Apply GridSearch CV\n",
        "                          param_grid = param_grid,\n",
        "                          scoring=\"f1\",\n",
        "                          cv=3,\n",
        "                          n_jobs = 1)\n",
        "logreg_grid.fit(X_train, y_train) # Train\n",
        "logreg_grid_best = logreg_grid.best_estimator_ # Best estimator\n",
        "print(\"Best Model Parameter: \",logreg_grid.best_params_) # Show best parameter\n",
        "print(logreg_grid_best)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Model Parameter:  {'C': 0.8, 'class_weight': {1: 0.8, 0: 0.2}, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "LogisticRegression(C=0.8, class_weight={0: 0.2, 1: 0.8}, dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhBRBct52xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4be2349-6ede-45bd-cec6-0410ac5cee9c"
      },
      "source": [
        "logreg = logreg_grid_best # Assign best parameter\n",
        "logreg.fit(X_train, y_train) # Retrain\n",
        "y_pred = logreg.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       0.57      0.13      0.21     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.78      0.56      0.60   1061313\n",
            "weighted avg       0.97      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVhYw3GUVVWu"
      },
      "source": [
        "### 7.2 Decision Tree with feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PY4MPI8BpsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4f929f-6fa3-44da-d3f6-895f44846451"
      },
      "source": [
        "params = {'max_leaf_nodes': [2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100], 'min_samples_split': [2, 3, 4]}\n",
        "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3) # Apply GridSearch CV\n",
        "grid_search_cv.fit(X_train, y_train) # Train\n",
        "grid_search_cv_best = grid_search_cv.best_estimator_ # Best parameter\n",
        "print(grid_search_cv_best) # Show best parameter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 63 candidates, totalling 189 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 189 out of 189 | elapsed: 71.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=42, splitter='best')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFftYHy5UAC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98857e3-6904-4089-b7fe-2bef31db31bb"
      },
      "source": [
        "print(\"Best Model Parameter: \",grid_search_cv.best_params_) # Best parameter\n",
        "print(grid_search_cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model Parameter:  {'max_leaf_nodes': 2, 'min_samples_split': 2}\n",
            "GridSearchCV(cv=3, error_score=nan,\n",
            "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
            "                                              criterion='gini', max_depth=None,\n",
            "                                              max_features=None,\n",
            "                                              max_leaf_nodes=None,\n",
            "                                              min_impurity_decrease=0.0,\n",
            "                                              min_impurity_split=None,\n",
            "                                              min_samples_leaf=1,\n",
            "                                              min_samples_split=2,\n",
            "                                              min_weight_fraction_leaf=0.0,\n",
            "                                              presort='deprecated',\n",
            "                                              random_state=42,\n",
            "                                              splitter='best'),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'max_leaf_nodes': [2, 5, 10, 15, 20, 25, 30, 35, 40,\n",
            "                                            45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
            "                                            90, 95, 100],\n",
            "                         'min_samples_split': [2, 3, 4]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-TpFhOeVe7M",
        "outputId": "8a7bce4f-cc9c-44b9-b44a-42b553f810db"
      },
      "source": [
        "decisiontree = grid_search_cv_best # Apply best parameter\n",
        "decisiontree.fit(X_train, y_train) # Retrain\n",
        "y_pred = decisiontree.predict(X_val) # Predict with test set\n",
        "print(classification_report(y_val, y_pred)) # Evaluate the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99   1040663\n",
            "           1       1.00      0.10      0.19     20650\n",
            "\n",
            "    accuracy                           0.98   1061313\n",
            "   macro avg       0.99      0.55      0.59   1061313\n",
            "weighted avg       0.98      0.98      0.98   1061313\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}